<!doctype html>
<meta charset="utf-8">
<script src="http://distill.pub/template.v1.js"></script>

<script type="text/front-matter">
  title: "Understanding the ANS Compressor"
  description: "understanding the Asymmetric Numeral Systems Compressor"
  authors:
  - Kedar Tatwawadi: https://github.com/kedartatwawadi
  affiliations:
  - Stanford University: http://stanford.edu
</script>


<!-- Katex -->
<!--<script src="assets/lib/auto-render.min.js"></script>-->
<!--<script src="assets/lib/katex.min.js"></script>-->
<link rel="stylesheet" href="assets/lib/katex.min.css">
<link rel="stylesheet" type="text/css" href="assets/widgets.css">

<!-- Required -->
<script src="assets/lib/lib.js"></script>
<script src="assets/utils.js"></script>
<script src="rANS.js"></script>
<script>
  var renderQueue = [];
  function renderMath(elem) {
    // renderMathInElement(
    //     elem,
    //     {
    //         delimiters: [
    //             {left: "$$", right: "$$", display: true},
    //             {left: "$", right: "$", display: false},
    //         ]
    //     }
    // );
  }
  var deleteQueue = [];
  function renderLoading(figure) {
    var loadingScreen = figure.append("svg")
    .style("width", figure.style("width"))
    .style("height", figure.style("height"))
    .style("position","absolute")
    .style("top", "0px")
    .style("left","0px")
    .style("background","white")
    .style("border", "0px dashed #DDD")
    .style("opacity", 1)
    return function(callback) { loadingScreen.remove() };
  }
</script>
<div id="math-cache" style="display: none;">
  <dt-math class="star">\star</dt-math>
  <dt-math class="plus">+</dt-math>
  <dt-math class="minus">-</dt-math>
  <dt-math class="equals">=</dt-math>
  <dt-math class="alpha">\alpha</dt-math>
  <dt-math class="lambda">\lambda</dt-math>
  <dt-math class="beta">\beta</dt-math>
  <dt-math class="r">R</dt-math>
  <dt-math class="alpha-equals">\alpha=</dt-math>
  <dt-math class="beta-equals">\beta=</dt-math>
  <dt-math class="beta-equals-zero">\beta = 0</dt-math>
  <dt-math class="beta-equals-one">\beta=1</dt-math>
  <dt-math class="alpha-equals-one-over-lambda-i">\alpha = 1/\lambda_i</dt-math>
  <dt-math class="model">\text{model}</dt-math>
  <dt-math class="p">0 p_1</dt-math>
  <dt-math class="phat">0 \bar{p}_1</dt-math>
  <dt-math class="two-sqrt-beta">2\sqrt{\beta}</dt-math>
  <dt-math class="lambda-i">\lambda_i</dt-math>
  <dt-math class="lambda-i-equals-zero">\lambda_i = 0</dt-math>
  <dt-math class="alpha-gt-one-over-lambda-i">\alpha > 1/\lambda_i</dt-math>
  <dt-math class="max-sigma-one">\max\{|\sigma_1|,|\sigma_2|\} > 1</dt-math>
  <dt-math class="x-i-k">x_i^k - x_i^*</dt-math>
  <dt-math class="xi-i">\xi_i</dt-math>
  <dt-math class="beta-equals-one-minus">\beta = (1 - \sqrt{\alpha \lambda_i})^2</dt-math>
</div>
<script>
  function MathCache(id) {
    return document.querySelector("#math-cache ." + id).innerHTML;
  }
</script>
<svg style="display: none;">
  <g id="pointerThingy">
    <circle fill="none" stroke="#FF6C00" stroke-linecap="round" cx="0" cy="0" r="14"/>
    <circle fill="#FF6C00" cx="0" cy="0" r="11"/>
    <path id="XMLID_173_" fill="#FFFFFF" d="M-3.2-1.3c0-0.1,0-0.2,0-0.3c0-0.1,0-0.2,0-0.3c-0.6,0-1.2,0-1.8,0c0,0.6,0,1.2,0,1.8
      c0.2,0,0.4,0,0.6,0c0-0.4,0-0.8,0-1.2c0,0,0.1,0,0.1,0c0.3,0,0.5,0,0.8,0C-3.4-1.3-3.3-1.3-3.2-1.3c0,0.2,0,0.4,0,0.6
      c0.2,0,0.4,0,0.6,0c0,0.2,0,0.4,0,0.6c0.2,0,0.4,0,0.6,0c0,0,0,0,0-0.1c0-1.6,0-3.2,0-4.8c0-0.6,0-1.2,0-1.8c0,0,0,0,0.1,0
      c0.3,0,0.7,0,1,0c0.1,0,0.1,0,0.2,0c0-0.2,0-0.4,0-0.6c-0.4,0-0.8,0-1.2,0C-2-7.2-2-7-2-6.8c0,0,0,0-0.1,0c-0.2,0-0.3,0-0.5,0
      c0,0,0,0-0.1,0c0,1.8,0,3.6,0,5.5c-0.2,0-0.3,0-0.4,0C-3.1-1.3-3.2-1.3-3.2-1.3z M1.1-3.7C1-3.8,1-3.8,1.1-3.7C1-4,1-4.1,1-4.3
      c0,0,0,0,0-0.1c-0.4,0-0.8,0-1.2,0c0-0.8,0-1.6,0-2.4c-0.2,0-0.4,0-0.6,0c0,1.8,0,3.6,0,5.5c0.2,0,0.4,0,0.6,0c0-0.8,0-1.6,0-2.4
      c0,0,0.1,0,0.1,0C0.3-3.7,0.6-3.7,1.1-3.7C1-3.7,1-3.7,1.1-3.7C1.1-3.7,1-3.7,1.1-3.7c0,0.8,0,1.6,0,2.3c0,0,0,0.1,0,0.1
      c0.2,0,0.4,0,0.6,0c0-0.6,0-1.2,0-1.8c0.4,0,0.8,0,1.2,0c0,0.8,0,1.6,0,2.4c0.2,0,0.4,0,0.6,0c0-0.6,0-1.2,0-1.8c0.2,0,0.4,0,0.6,0
      c0,0,0,0,0,0.1c0,0.1,0,0.3,0,0.4c0,0,0,0.1,0,0.1c0.2,0,0.4,0,0.5,0c0,0,0.1,0,0.1,0.1c0,0.2,0,0.5,0,0.7c0,1.1,0,2.3,0,3.4
      c0,0,0,0,0,0.1c-0.2,0-0.4,0-0.6,0c0,0,0,0,0,0c0,0.6,0,1.1,0,1.7c0,0,0,0,0,0.1c-0.2,0-0.4,0-0.6,0c0,0.4,0,0.8,0,1.2
      c-1.6,0-3.2,0-4.9,0c0-0.4,0-0.8,0-1.2c-0.2,0-0.4,0-0.6,0C-2,3.8-2,3.4-2,3c-0.2,0-0.4,0-0.6,0c0,0.4,0,0.8,0,1.2
      c0.2,0,0.4,0,0.6,0C-2,4.8-2,5.4-2,6c2,0,4.1,0,6.1,0c0-0.1,0-0.2,0-0.3c0-0.5,0-0.9,0-1.4c0-0.1,0-0.1,0-0.2c0.2,0,0.4,0,0.5,0
      c0.1,0,0.1,0,0.1-0.1c0-0.4,0-0.9,0-1.3c0-0.1,0-0.3,0-0.4c0.1,0,0.2,0,0.3,0c0.1,0,0.2,0,0.3,0c0-1.4,0-2.8,0-4.3
      c-0.2,0-0.4,0-0.6,0c0-0.2,0-0.4,0-0.6c-0.2,0-0.4,0-0.6,0c0-0.2,0-0.4,0-0.6c-0.4,0-0.8,0-1.2,0c0-0.2,0-0.4,0-0.6
      c-0.1,0-0.2,0-0.3,0c-0.4,0-0.9,0-1.3,0C1.2-3.7,1.1-3.7,1.1-3.7z M-3.2,1.8c0,0.4,0,0.8,0,1.2c0.2,0,0.4,0,0.5,0
      c0.1,0,0.1,0,0.1-0.1c0-0.3,0-0.6,0-1c0-0.1,0-0.1,0-0.2C-2.8,1.8-3,1.8-3.2,1.8c0-0.4,0-0.8,0-1.2c-0.2,0-0.4,0-0.6,0
      c0-0.2,0-0.4,0-0.6c-0.2,0-0.4,0-0.6,0c0,0.2,0,0.4,0,0.6c0.2,0,0.4,0,0.6,0c0,0,0,0,0,0.1c0,0.1,0,0.3,0,0.4c0,0.2,0,0.5,0,0.7
      c0,0,0,0.1,0.1,0.1c0.1,0,0.2,0,0.3,0C-3.4,1.8-3.3,1.8-3.2,1.8z"/>
    <path id="XMLID_172_" fill="#FFFFFF" d="M4.1,4.2C4.1,4.2,4.1,4.2,4.1,4.2c0-0.6,0-1.2,0-1.8c0,0,0,0,0,0c0.2,0,0.4,0,0.6,0
      c0,0,0-0.1,0-0.1c0-1.1,0-2.3,0-3.4c0-0.2,0-0.5,0-0.7c0,0,0-0.1-0.1-0.1c-0.2,0-0.4,0-0.5,0c0,0,0-0.1,0-0.1c0-0.1,0-0.3,0-0.4
      c0,0,0-0.1,0-0.1c-0.2,0-0.4,0-0.6,0c0,0.6,0,1.2,0,1.8c-0.2,0-0.4,0-0.6,0c0-0.8,0-1.6,0-2.4c-0.4,0-0.8,0-1.2,0
      c0,0.6,0,1.2,0,1.8c-0.2,0-0.4,0-0.6,0c0,0,0-0.1,0-0.1c0-0.7,0-1.5,0-2.2c0,0,0-0.1,0-0.1l0,0c0.1,0,0.2,0,0.2,0
      c0.4,0,0.9,0,1.3,0c0.1,0,0.2,0,0.3,0c0,0.2,0,0.4,0,0.6c0.4,0,0.8,0,1.2,0c0,0.2,0,0.4,0,0.6c0.2,0,0.4,0,0.6,0c0,0.2,0,0.4,0,0.6
      c0.2,0,0.4,0,0.6,0c0,1.4,0,2.8,0,4.3c-0.1,0-0.2,0-0.3,0c-0.1,0-0.2,0-0.3,0c0,0.1,0,0.3,0,0.4c0,0.4,0,0.9,0,1.3
      c0,0.1,0,0.1-0.1,0.1C4.5,4.2,4.3,4.2,4.1,4.2L4.1,4.2z"/>
    <path id="XMLID_171_" fill="#FFFFFF" d="M4.1,4.2c0,0.1,0,0.1,0,0.2c0,0.5,0,0.9,0,1.4c0,0.1,0,0.2,0,0.3C2.1,6,0,6-2,6
      c0-0.6,0-1.2,0-1.8c-0.2,0-0.4,0-0.6,0c0-0.4,0-0.8,0-1.2C-2.4,3-2.2,3-2,3c0,0.4,0,0.8,0,1.2c0.2,0,0.4,0,0.6,0c0,0.4,0,0.8,0,1.2
      c1.6,0,3.2,0,4.9,0c0-0.4,0-0.8,0-1.2C3.7,4.2,3.9,4.2,4.1,4.2L4.1,4.2z"/>
    <path id="XMLID_170_" fill="#FFFFFF" d="M-2-6.8c0,0.6,0,1.2,0,1.8c0,1.6,0,3.2,0,4.8c0,0,0,0,0,0.1c-0.2,0-0.4,0-0.6,0
      c0-0.2,0-0.4,0-0.6c-0.2,0-0.4,0-0.6,0c0-0.2,0-0.4,0-0.6l0,0c0.1,0,0.1,0,0.2,0c0.1,0,0.3,0,0.4,0c0-1.8,0-3.6,0-5.5
      c0,0,0.1,0,0.1,0C-2.4-6.8-2.2-6.8-2-6.8C-2.1-6.8-2-6.8-2-6.8L-2-6.8z"/>
    <path id="XMLID_169_" fill="#FFFFFF" d="M1.1-3.7C1-3.7,1-3.7,1.1-3.7c-0.4,0-0.8,0-1.2,0c0,0,0,0-0.1,0c0,0.8,0,1.6,0,2.4
      c-0.2,0-0.4,0-0.6,0c0-1.8,0-3.6,0-5.5c0.2,0,0.4,0,0.6,0c0,0.8,0,1.6,0,2.4c0.4,0,0.8,0,1.2,0c0,0,0,0.1,0,0.1C1-4.1,1-4,1.1-3.7
      C1-3.8,1-3.8,1.1-3.7L1.1-3.7z"/>
    <path id="XMLID_168_" fill="#FFFFFF" d="M-3.2,1.8c-0.1,0-0.2,0-0.3,0c-0.1,0-0.2,0-0.3,0c0,0-0.1,0-0.1-0.1c0-0.2,0-0.5,0-0.7
      c0-0.1,0-0.3,0-0.4c0,0,0,0,0-0.1c-0.2,0-0.4,0-0.6,0c0-0.2,0-0.4,0-0.6c0.2,0,0.4,0,0.6,0c0,0.2,0,0.4,0,0.6c0.2,0,0.4,0,0.6,0
      C-3.2,0.9-3.2,1.3-3.2,1.8c0.2,0,0.4,0,0.6,0c0,0.1,0,0.1,0,0.2c0,0.3,0,0.6,0,1C-2.6,3-2.7,3-2.7,3c-0.2,0-0.3,0-0.5,0
      C-3.2,2.6-3.2,2.2-3.2,1.8z"/>
    <path id="XMLID_167_" fill="#FFFFFF" d="M-3.2-1.3c-0.1,0-0.2,0-0.3,0c-0.3,0-0.5,0-0.8,0c0,0,0,0-0.1,0c0,0.4,0,0.8,0,1.2
      c-0.2,0-0.4,0-0.6,0c0-0.6,0-1.2,0-1.8c0.6,0,1.2,0,1.8,0c0,0.1,0,0.2,0,0.3C-3.2-1.5-3.2-1.4-3.2-1.3L-3.2-1.3z"/>
    <path id="XMLID_166_" fill="#FFFFFF" d="M-2-6.8C-2-7-2-7.2-2-7.4c0.4,0,0.8,0,1.2,0c0,0.2,0,0.4,0,0.6c-0.1,0-0.1,0-0.2,0
      C-1.3-6.8-1.6-6.8-2-6.8C-2-6.8-2-6.8-2-6.8L-2-6.8z"/>
  </g>
</svg>

<dt-article class="centered">
  <h1>What is ANS?</h1>
  <h2>Understanding the new entropy coder: Asymmetric Numeral Systems</h2>
  <dt-byline></dt-byline>
  <p>Recently while attending a talk at the Stanford Compression Forum, I heard about a new class of entropy coders called the Asymmetric Numeral Systems coders (ANS). Considering Arithmetic coding and Huffman coding have essentially resolved the problem of entropy coding, it is surprising that there is a new development in the field of entropy coding. Today, just a few years after the original paper came out, ANS has already been incorporated into numerous compressors, including Zstandard (facebook), LZFSE (Apple), CRAM (Genomic SAM file compression) etc. I was curious to understand what exactly did this new kid on the block did, but found the original paper pretty difficult to follow. Thanks to some amazing and detailed blog posts, I was able to make some sense out of the paper! The ANS Coder is not a single compressor but a class of entropy coders for a given distribution. The most important thing they achieve is achieving very accurate compression (similar to Arithmetic coding) ,but at very high compression and decompression speeds (like Pied Piper, ANS significantly improves upon the Weissman score :) ). </p>

  <p> In this series of posts, we will try to improve our understanding of the ANS family of coders. But before we do that, lets revise the two most important entropy coders we have: Huffman and Arithmetic Coders. </p>

  <h2> Huffman and Arithmetic Coders </h2>
  <p>
  Huffman coding (and for that matter any prefix-free codes) are the fastest entropy coders, as all they do is table-lookup for encoding, where there is a unique prefix-free code for every input alphabet. The prefix-free nature of the codes allows for efficient decoding. One can also imagine huffman coding being a Finite State Entropy coder (FSE), with a single state. For every input alphabet, we output the corresponding prefix-free code (from the lookup-table) and transition back to the same state. We also know that even the best prefix encoder: Huffman coder can be significantly suboptimal in terms of compression, with a gap with the entropy as high as <dt-math> 1 bit/symbol </dt-math>. </p>

  <p> On the other extreme we have the family of Arithmetic coders. Arithmetic coding can be thought of as an encoder which implicitly represents the entire input as a single state from a huge Finite-State automata (whose size is asymtotically exponential in the length of the input). Arithmetic coding is optimal in terms of its compression, but has slower compression/decompression speeds. If you brush up your memory (or look here: <dt-cite key="gregor2015draw"></dt-cite>) , you would remember that Arithmetic coding subdivides the <i>range</i> which it maintains as a state and thus uses the <i>division</i> operation at every step (both during compression and decompression), which is the main reason for it being slow. </p>

  <p> The ANS family of coders forms the bridge between these two extremes of entropy coders, where we can design a k-state FSE coder (for a wide range of <dt-math> k </dt-math> values), which results in better compression optimality than Huffman coding with a slight decrease in the speed. This ability of graceful tradeoff between the compression vs speed is crucial to what makes the ANS family so useful in practice.  We will first look at one member of the ANS family of coders: <b>rANS</b>, which is an acronym for range-ANS due to its similarities to the arithmetic encoder.   
  </p>

 <h2> rANS </h2>
 <p>
 Before we describe rANS, some notation: 
 <ol>
  <li> Let <dt-math>S = (s_1,s_2,s_3,\ldots, s_n) </dt-math> be the input string of symbols from the alphabet set <dt-math> \mathcal{A} = \{a_1,a_2,\ldots,a_k \}</dt-math> of size <dt-math>k</dt-math>
  <li> We assume the data comes from a distribution characterized by the frequency counts <dt-math> \mathcal{F} = \{ F_{a_1}, F_{a_2},\ldots, F_{a_k} \} </dt-math>, which are integers proportional to the probability mass distribution <dt-math>(p_1,p_2,\ldots,p_k)</dt-math> of the symbols.
    <br>
  Let <dt-math> M = \sum_{i=1}^k F_i </dt-math>. Then, <dt-math> p_i = \frac{F_{a_i}}{M} </dt-math>
  <li> We also define the cumulative frequency counts <dt-math> C_{a_i} = \sum_{j=1}^{i-1} F_{a_j} </dt-math>, which correspond to the cumulative distribution of the symbols
  </ol>
  </p>
  <p> <b>Example:</b> Let the alphabet be <dt-math> \mathcal{A} = \{ A,B,C\} </dt-math>. Then, we can consider input generated using frequency counts <dt-math> F = \{ 3, 3, 2\} </dt-math>, which corresponds to probabilities <dt-math> \{ \frac{3}{8}, \frac{3}{8}, \frac{2}{8} \} </dt-math>. 
  <br> The cumulative frequency counts in this case corresponds to <dt-math> C = \{ 0, 3, 6 \} </dt-math>
  </p>
  <!-- <li> rANS keeps track of the input using a single integer state. Let <dt-math> X_t </dt-math> represent the integer state of rANS after it has looked at <dt-math> t </dt-math> input symbols. <dt-math> X_0 = 1 </dt-math> is the initial state of rANS. <dt-math> X_t </dt-math> is a function of the previous state <dt-math> X_{t-1} </dt-math> and the current symbol <dt-math> s_t </dt-math>
    <dt-math block>  X_t = C_{rANS}(X_{t-1},s_t)</dt-math>
  <li> The compression output is the state <dt-math> X_n </dt-math> represented using <dt-math> ceil(\log_2 X_n) </dt-math> bits. <dt-math> X_n </dt-math> (along with the number of symbols encoded: <dt-math> n </dt-math>) is used to decode the entire input string <dt-math> S </dt-math>
    <dt-math block>  s_t, X_{t-1} = D_{rANS}(X_{t})</dt-math> -->

   <h3> rANS Encoding & Decoding </h3>
   <p>
   We are now all set to describe the rANS encoding. We will first describe the encoding and decoding functions in their full glory, and then try to understand their operations using simple examples. So here it goes: 
   </p>
  <p>

   <dt-math block> 
      X_t = floor \left( \frac{X_{t-1}}{F_{s_t}} \right) * M + C_{s_t} + mod(X_{t-1}, F_{s_t}) 
   </dt-math>
    
   Thats all! This is the encoding step for the rANS. Lets also state the decoder for completeness. 
   
   Let <dt-math> C\_inv(y) </dt-math> be the inverse function of the cumulative frequency, where: <dt-math> C\_inv(y) = a_i </dt-math>, if <dt-math> C_{a_i} \leq y  < C_{a_{i+1}} </dt-math>. Then, the decoder, <dt-math>D_{rANS}(X_{t})</dt-math> is defined as follows:

   <dt-math block> 
      \begin{aligned}
      slot &= mod(X_t,M) \\
      s_t  &= C\_inv(slot) \\
      X_{t-1} &= floor \left( X_t/M \right) * F_{s_t} + slot - C_{s_t} 
      \end{aligned}
   </dt-math>
   
   </p>
   <p>
   One can understand rANS encoding as a 2-step process:
   <ol>
     <li> In the first step, we choose a <dt-math> M </dt-math> sized block. For a state <dt-math> X_{t-1} </dt-math>, we choose the block with  <dt-math> blockId = floor \left( \frac{X_{t-1}}{F_{s_t}} \right) </dt-math>. 
     <li> Once the <dt-math> blockId </dt-math> is fixed, we choose a <dt-math> slot </dt-math>, out of the <dt-math> M </dt-math> allowed integers from the block. For the next symbol being <dt-math> s_t </dt-math>, the <dt-math> slot </dt-math> can be chosen in the range <dt-math> [C_{s_t},C_{s_{t} + 1}-1] </dt-math>.
     <li> The next state <dt-math> X_t </dt-math> then is composed of as: <dt-math> X_t = blockId*M + slot </dt-math> 
     <li> Having distinct ranges for every symbol makes it possible to decode <dt-math> s_t </dt-math>, by only looking at: 
    <dt-math> slot = mod(X_t,M) </dt-math> during the decoding, using the <dt-math> C\_inv </dt-math> function.
     <li> During the decoding, we can also retrieve the  <dt-math> blockId </dt-math> from the state <dt-math> X_t </dt-math> as: <dt-math> floor \left( X_t/M \right) </dt-math>. Now the only missing piece of information required to retrieve <dt-math> X_{t-1} </dt-math> is <dt-math> mod(X_{t-1}, F_{s_t}) </dt-math>. We can very amazingly also accomodate this information during the encoding, by choosing the <dt-math> slot </dt-math> ID to be <dt-math> C_{s_t} + mod(X_{t-1}, F_{s_t}) </dt-math>, which lies in the allowed range of <dt-math> [C_{s_t},C_{s_{t} + 1}-1] </dt-math>.
    </ol>
   </p>
   <h4> rANS Encoding Example</h4>
   <p> The following snippet can be used to try out the rANS encoding to ge an idea </p>
   <p>
   Symbol Counts, <dt-math> \mathcal{F} </dt-math> <input type="text" id="symbol_counts" value="3,3,2"> <br>
   Input Symbol String: <input type="text" id="input_text" value="0,1,0,2,2,0,1,0"> <br>
   <button onclick="rANS_encoder()">Try it</button> 
   </p>
   <p id="demo"></p>


   <h4> rANS Decoding </h4>
   <p> You can input the state and other info from the encoding to verify that the encoding is indeed correct </p>
   <p>
   Symbol Counts, <dt-math> \mathcal{F} </dt-math> <input type="text" id="symbol_counts_decoder" value="3,3,2"> <br>
   State <input type="text" id="state_decoder" value="3017"> <br>
   Number of Encoded Symbols <input type="text" id="num_decoder" value="8"> <br>
   <button onclick="rANS_decoder()">Try it</button> 
   </p>
   <p id="rANS_decoder"></p>
  
  <p>
  We also present python function scripts (which is more of a pseudo-code) to play around with. 

  <dt-code block language="python">
  # rANS Encoder code. Not optimized in any way
  # Mainly for playing around 
  def rANS_encoder(s_input, symbol_counts):
    total_counts = np.sum(symbol_counts)  #Represents M
    cumul_sum = np.insert(np.cumsum(symbol_counts),0,0) #Cumul_sum represents the cumulative frequencies
    num_symbols = len(s_input) #the length of the input
    
    state = 1 #Initialize the state
    for s in s_input:
      s_count = symbol_counts[s] #current symbol count/frequency
      state = (state/s_count)*total_counts + cumul_sum[s] + (state % s_count) #Main encoding step

    return state, num_symbols
   </dt-code>

   <dt-code block language="python">
  #rANS Decoder code. Not optimized in any way
  #Mainly for playing around 
  def rANS_decoder(state, num_symbols, symbol_counts):
    total_counts = np.sum(symbol_counts)  #Represents M
    cumul_sum = np.insert(np.cumsum(symbol_counts),0,0) #Cumul_sum represents the cumulative frequencies

    #The Cumulative frequency inverse function
    def cumul_inverse(y): 
      for i,_s in enumerate(cumul_sum): 
        if y < _s: return i-1

    s_decoded = []  #Initialize a list to hold the decoded symbols
    while len(s_decoded) < num_symbols: #continue decoding until all symbols decoded
      slot = state % total_counts #compute the slot     
      s = cumul_inverse(y) #decode the symbol
      s_decoded.append(s) 
      state = (state/total_counts)*symbol_count[s] + slot - cumul_sum[s] #update the state

    return x_decoded
   </dt-code>

  <h4> Optimality of rANS </h4>
  <p>
  Now that we have convinced ourselves that rANS indeed is a lossless codec, lets see why rANS achieves the optimal compression ratio. Notice that: 
  
  <dt-math block>  
    \begin{align}
    \frac{X_t}{X_{t-1}} &\approx p(s_t) &= \frac{M}{F_{s_t}} \\
    \frac{X_n}{X_{0}} &\approx \prod_{t=1}^n p(s_t) \\
    \end{align}
  </dt-math>


  </p>

   


  <p>We can also cite <dt-cite key="gregor2015draw"></dt-cite> external publications.</p>
</dt-article>

<dt-appendix>
</dt-appendix>

<script type="text/bibliography">
  @article{gregor2015draw,
    title={DRAW: A recurrent neural network for image generation},
    author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
    journal={arXivreprint arXiv:1502.04623},
    year={2015},
    url={https://arxiv.org/pdf/1502.04623.pdf}
  }
</script>